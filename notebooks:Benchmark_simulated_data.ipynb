{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /opt/anaconda3/envs/pytorch/bin/python\n",
      "Python path: ['/opt/anaconda3/envs/pytorch/lib/python39.zip', '/opt/anaconda3/envs/pytorch/lib/python3.9', '/opt/anaconda3/envs/pytorch/lib/python3.9/lib-dynload', '', '/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages', '/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/setuptools/_vendor', '/var/folders/3k/wtktqhhs2szgg7m8yyz29zgr0000gn/T/tmpjl0yie3z', '/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages']\n",
      "Scanpy imported successfully!\n",
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../R/simulated_data/imbalanced_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m nb_genes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3000\u001b[39m\n\u001b[1;32m     39\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 40\u001b[0m files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mR/simulated_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mR/simulated_data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcategory\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     42\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     44\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphConv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../R/simulated_data/imbalanced_data'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import scanpy as sc\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "import train\n",
    "import models\n",
    "\n",
    "# 固定随机种子\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# 定义全局参数\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "category = \"imbalanced_data\"\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "pca_size = 50\n",
    "nb_genes = 3000\n",
    "\n",
    "path = \"../\"\n",
    "files = [f\"{path}R/simulated_data/{category}/{file}.h5\" for file in os.listdir(f\"{path}R/simulated_data/{category}\") if file.endswith(\".h5\")]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "model_name = \"GraphConv\"\n",
    "normalize_weights = \"per_cell\"\n",
    "node_features = \"scale\"\n",
    "hidden_relu = False\n",
    "hidden_bn = False\n",
    "n_layers = 1\n",
    "hidden_dim = 200\n",
    "hidden = [300]\n",
    "activation = F.relu\n",
    "\n",
    "# 创建输出路径\n",
    "output_dir = f\"../output/pickle_results/{category}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 数据集循环\n",
    "for dataset_path in files:\n",
    "    dataset_name = os.path.basename(dataset_path).replace(\".h5\", \"\")\n",
    "    print(f\">> Processing dataset: {dataset_name}\")\n",
    "\n",
    "    # 加载数据\n",
    "    data_mat = h5py.File(dataset_path, \"r\")\n",
    "    Y = np.array(data_mat['Y'])\n",
    "    X = np.array(data_mat['X'])\n",
    "\n",
    "    # 数据过滤\n",
    "    genes_idx, cells_idx = train.filter_data(X, highly_genes=nb_genes)\n",
    "    X = X[cells_idx][:, genes_idx]\n",
    "    Y = Y[cells_idx]\n",
    "    n_clusters = len(np.unique(Y))\n",
    "\n",
    "    # 构建图\n",
    "    t0 = time.time()\n",
    "    edge_index, node_feats, labels = train.make_graph_pyg(\n",
    "        X,\n",
    "        Y,\n",
    "        dense_dim=pca_size,\n",
    "        normalize_weights=normalize_weights,\n",
    "    )\n",
    "\n",
    "    # 创建 PyG Data 对象\n",
    "    graph_data = Data(\n",
    "        x=torch.tensor(node_feats, dtype=torch.float),\n",
    "        edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "        y=torch.tensor(labels, dtype=torch.long),\n",
    "    )\n",
    "\n",
    "    # 训练节点 ID\n",
    "    train_ids = (graph_data.y != -1).nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "    # 使用 NeighborLoader 进行采样\n",
    "    sampler_loader = NeighborLoader(\n",
    "        graph_data,\n",
    "        input_nodes=train_ids,\n",
    "        num_neighbors=[-1],  # 全邻居\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    print(f\"INPUT: {model_name} {hidden_dim}, {hidden}\")\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    # 模型训练与评估\n",
    "    for run in range(3):\n",
    "        t_start = time.time()\n",
    "        torch.manual_seed(run)\n",
    "        torch.cuda.manual_seed_all(run)\n",
    "        np.random.seed(run)\n",
    "        random.seed(run)\n",
    "\n",
    "        model = models.GCNAE(\n",
    "            in_feats=pca_size,\n",
    "            n_hidden=hidden_dim,\n",
    "            n_layers=n_layers,\n",
    "            activation=activation,\n",
    "            dropout=0.1,\n",
    "            hidden=hidden,\n",
    "            hidden_relu=hidden_relu,\n",
    "            hidden_bn=hidden_bn,\n",
    "        ).to(device)\n",
    "        if run == 0:\n",
    "            print(\">\", model)\n",
    "\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "        # 调用训练函数\n",
    "        scores = train.train(\n",
    "            model,\n",
    "            optim,\n",
    "            epochs,\n",
    "            sampler_loader,\n",
    "            n_clusters,\n",
    "            plot=False,\n",
    "            cluster=[\"KMeans\", \"Leiden\"],\n",
    "            cluster_params={\"Leiden\": {\"resolution\": 1.0}},\n",
    "        )\n",
    "\n",
    "        # 记录结果\n",
    "        scores[\"dataset\"] = dataset_name\n",
    "        scores[\"run\"] = run\n",
    "        scores[\"nb_genes\"] = nb_genes\n",
    "        scores[\"hidden\"] = str(hidden)\n",
    "        scores[\"hidden_dim\"] = hidden_dim\n",
    "        scores[\"tot_kmeans_time\"] = (t1 - t0) + (scores['ae_end'] - t_start) + scores.get('kmeans_time', 0)\n",
    "        scores[\"tot_leiden_time\"] = (t1 - t0) + (scores['ae_end'] - t_start) + scores.get('leiden_time', 0)\n",
    "\n",
    "        # 将结果存储到 DataFrame\n",
    "        results = pd.concat([results, pd.DataFrame([scores])], ignore_index=True)\n",
    "\n",
    "        # 保存结果到文件\n",
    "        results.to_pickle(os.path.join(output_dir, f\"{category}_gae.pkl\"))\n",
    "        print(f\"Completed run {run} for dataset {dataset_name}.\")\n",
    "\n",
    "print(\"Final results summary:\")\n",
    "print(results.groupby(\"dataset\").mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
