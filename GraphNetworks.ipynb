{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: <HDF5 dataset \"X\": shape (777, 16270), type \"<f4\">\n",
      "obs: <HDF5 group \"/obs\" (2 members)>\n",
      "obs/Group: <HDF5 dataset \"Group\": shape (777,), type \"<i8\">\n",
      "obs/cell_id: <HDF5 dataset \"cell_id\": shape (777,), type \"|O\">\n",
      "var: <HDF5 group \"/var\" (1 members)>\n",
      "var/gene_id: <HDF5 dataset \"gene_id\": shape (16270,), type \"|O\">\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "data_path = \"./Camp.h5\"\n",
    "with h5py.File(data_path, \"r\") as f:\n",
    "    def print_keys(name, obj):\n",
    "        print(f\"{name}: {obj}\")\n",
    "    f.visititems(print_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: ['Camp']\n",
      "Processing dataset: Camp\n",
      "Data shape: (777, 16270), Labels shape: (777,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3k/wtktqhhs2szgg7m8yyz29zgr0000gn/T/ipykernel_5954/740914094.py:49: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  X = np.array(f['X'])  # 矩阵形状 (777, 16270)\n",
      "/var/folders/3k/wtktqhhs2szgg7m8yyz29zgr0000gn/T/ipykernel_5954/740914094.py:51: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  Y = np.array(f['obs']['Group'])  # 标签形状 (777,)\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py:251: UserWarning: If you pass `n_top_genes`, all cutoffs are ignored.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Info - Nodes: 2777, Edges: 414710\n",
      ">> Training Model: GCNConv | Run: 0\n",
      "Epoch 1/10, Loss: 0.4733\n",
      "Epoch 2/10, Loss: 0.4733\n",
      "Epoch 3/10, Loss: 0.4733\n",
      "Epoch 4/10, Loss: 0.4733\n",
      "Epoch 5/10, Loss: 0.4733\n",
      "Epoch 6/10, Loss: 0.4733\n",
      "Epoch 7/10, Loss: 0.4733\n",
      "Epoch 8/10, Loss: 0.4733\n",
      "Epoch 9/10, Loss: 0.4733\n",
      "Epoch 10/10, Loss: 0.4733\n",
      ">> Training Model: GCNConv | Run: 1\n",
      "Epoch 1/10, Loss: 0.4734\n",
      "Epoch 2/10, Loss: 0.4734\n",
      "Epoch 3/10, Loss: 0.4734\n",
      "Epoch 4/10, Loss: 0.4734\n",
      "Epoch 5/10, Loss: 0.4734\n",
      "Epoch 6/10, Loss: 0.4734\n",
      "Epoch 7/10, Loss: 0.4734\n",
      "Epoch 8/10, Loss: 0.4734\n",
      "Epoch 9/10, Loss: 0.4734\n",
      "Epoch 10/10, Loss: 0.4734\n",
      ">> Training Model: GCNConv | Run: 2\n",
      "Epoch 1/10, Loss: 0.4735\n",
      "Epoch 2/10, Loss: 0.4735\n",
      "Epoch 3/10, Loss: 0.4735\n",
      "Epoch 4/10, Loss: 0.4735\n",
      "Epoch 5/10, Loss: 0.4735\n",
      "Epoch 6/10, Loss: 0.4735\n",
      "Epoch 7/10, Loss: 0.4735\n",
      "Epoch 8/10, Loss: 0.4735\n",
      "Epoch 9/10, Loss: 0.4735\n",
      "Epoch 10/10, Loss: 0.4735\n",
      ">> Training Model: GraphConv | Run: 0\n",
      "Epoch 1/10, Loss: 0.3293\n",
      "Epoch 2/10, Loss: 0.3289\n",
      "Epoch 3/10, Loss: 0.3290\n",
      "Epoch 4/10, Loss: 0.3289\n",
      "Epoch 5/10, Loss: 0.3288\n",
      "Epoch 6/10, Loss: 0.3289\n",
      "Epoch 7/10, Loss: 0.3289\n",
      "Epoch 8/10, Loss: 0.3286\n",
      "Epoch 9/10, Loss: 0.3287\n",
      "Epoch 10/10, Loss: 0.3289\n",
      ">> Training Model: GraphConv | Run: 1\n",
      "Epoch 1/10, Loss: 0.3270\n",
      "Epoch 2/10, Loss: 0.3271\n",
      "Epoch 3/10, Loss: 0.3274\n",
      "Epoch 4/10, Loss: 0.3271\n",
      "Epoch 5/10, Loss: 0.3275\n",
      "Epoch 6/10, Loss: 0.3268\n",
      "Epoch 7/10, Loss: 0.3270\n",
      "Epoch 8/10, Loss: 0.3269\n",
      "Epoch 9/10, Loss: 0.3268\n",
      "Epoch 10/10, Loss: 0.3274\n",
      ">> Training Model: GraphConv | Run: 2\n",
      "Epoch 1/10, Loss: 0.3310\n",
      "Epoch 2/10, Loss: 0.3311\n",
      "Epoch 3/10, Loss: 0.3313\n",
      "Epoch 4/10, Loss: 0.3310\n",
      "Epoch 5/10, Loss: 0.3310\n",
      "Epoch 6/10, Loss: 0.3310\n",
      "Epoch 7/10, Loss: 0.3311\n",
      "Epoch 8/10, Loss: 0.3310\n",
      "Epoch 9/10, Loss: 0.3306\n",
      "Epoch 10/10, Loss: 0.3312\n",
      ">> Training Model: GATConv | Run: 0\n",
      "Epoch 1/10, Loss: 0.4740\n",
      "Epoch 2/10, Loss: 0.4740\n",
      "Epoch 3/10, Loss: 0.4740\n",
      "Epoch 4/10, Loss: 0.4740\n",
      "Epoch 5/10, Loss: 0.4740\n",
      "Epoch 6/10, Loss: 0.4740\n",
      "Epoch 7/10, Loss: 0.4740\n",
      "Epoch 8/10, Loss: 0.4740\n",
      "Epoch 9/10, Loss: 0.4740\n",
      "Epoch 10/10, Loss: 0.4740\n",
      ">> Training Model: GATConv | Run: 1\n",
      "Epoch 1/10, Loss: 0.4740\n",
      "Epoch 2/10, Loss: 0.4740\n",
      "Epoch 3/10, Loss: 0.4740\n",
      "Epoch 4/10, Loss: 0.4740\n",
      "Epoch 5/10, Loss: 0.4740\n",
      "Epoch 6/10, Loss: 0.4740\n",
      "Epoch 7/10, Loss: 0.4740\n",
      "Epoch 8/10, Loss: 0.4740\n",
      "Epoch 9/10, Loss: 0.4740\n",
      "Epoch 10/10, Loss: 0.4740\n",
      ">> Training Model: GATConv | Run: 2\n",
      "Epoch 1/10, Loss: 0.4741\n",
      "Epoch 2/10, Loss: 0.4741\n",
      "Epoch 3/10, Loss: 0.4741\n",
      "Epoch 4/10, Loss: 0.4741\n",
      "Epoch 5/10, Loss: 0.4741\n",
      "Epoch 6/10, Loss: 0.4741\n",
      "Epoch 7/10, Loss: 0.4741\n",
      "Epoch 8/10, Loss: 0.4741\n",
      "Epoch 9/10, Loss: 0.4740\n",
      "Epoch 10/10, Loss: 0.4740\n",
      "Mean results grouped by model_name:\n",
      "            kmeans_ari  kmeans_nmi  leiden_ari  leiden_nmi  run  nb_genes  \\\n",
      "model_name                                                                  \n",
      "GATConv       0.121681    0.335938    0.085619    0.418246  1.0    2000.0   \n",
      "GCNConv       0.599600    0.733412    0.121808    0.534302  1.0    2000.0   \n",
      "GraphConv     0.970598    0.819920    0.120298    0.520161  1.0    2000.0   \n",
      "\n",
      "            hidden_dim  \n",
      "model_name              \n",
      "GATConv          200.0  \n",
      "GCNConv          200.0  \n",
      "GraphConv        200.0  \n",
      "Mean results grouped by dataset:\n",
      "         kmeans_ari  kmeans_nmi  leiden_ari  leiden_nmi  run  nb_genes  \\\n",
      "dataset                                                                  \n",
      "Camp        0.56396    0.629757    0.109242    0.490903  1.0    2000.0   \n",
      "\n",
      "         hidden_dim  \n",
      "dataset              \n",
      "Camp          200.0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, GraphConv, GATConv  # 直接导入 GNN 层\n",
    "from train import filter_data, make_graph_pyg\n",
    "from models import GCNAE\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "# 固定随机种子\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# 参数设置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "category = \"real_data\"\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "pca_size = 50\n",
    "path = \"./\"  # 当前目录\n",
    "files = [\"Camp\"]\n",
    "print(\"Datasets:\", files)\n",
    "\n",
    "nb_genes = 2000\n",
    "hidden_dim = 200\n",
    "activation = F.relu\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# 定义模型映射\n",
    "gnn_layer_map = {\n",
    "    \"GCNConv\": GCNConv,\n",
    "    \"GraphConv\": GraphConv,\n",
    "    \"GATConv\": GATConv,\n",
    "}\n",
    "\n",
    "# 主循环\n",
    "for dataset in files:\n",
    "    print(f\"Processing dataset: {dataset}\")\n",
    "    \n",
    "    # 加载数据\n",
    "    data_path = os.path.join(path, f\"{dataset}.h5\")\n",
    "    with h5py.File(data_path, \"r\") as f:\n",
    "        # 数据矩阵\n",
    "        X = np.array(f['X'])  # 矩阵形状 (777, 16270)\n",
    "        # 标签（Group列）\n",
    "        Y = np.array(f['obs']['Group'])  # 标签形状 (777,)\n",
    "\n",
    "    print(f\"Data shape: {X.shape}, Labels shape: {Y.shape}\")\n",
    "\n",
    "    # 数据过滤和PCA\n",
    "    genes_idx, cells_idx = filter_data(X, highly_genes=nb_genes)\n",
    "    X = X[cells_idx][:, genes_idx]  # 过滤后的数据\n",
    "    Y = Y[cells_idx]  # 过滤后的标签\n",
    "    n_clusters = len(np.unique(Y))\n",
    "\n",
    "    # 构建图数据\n",
    "    edge_index, node_features, labels = make_graph_pyg(\n",
    "        X,\n",
    "        Y=Y,\n",
    "        threshold=0,\n",
    "        dense_dim=pca_size,\n",
    "        normalize_weights=\"log_per_cell\",\n",
    "    )\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    pyg_data = Data(x=node_features, edge_index=edge_index, y=labels)\n",
    "    dataloader = DataLoader([pyg_data], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    print(f\"Graph Info - Nodes: {pyg_data.num_nodes}, Edges: {pyg_data.num_edges}\")\n",
    "\n",
    "    for model_name, gnn_layer in gnn_layer_map.items():\n",
    "        for run in range(3):\n",
    "            # 模型初始化\n",
    "            torch.manual_seed(run)\n",
    "            torch.cuda.manual_seed_all(run)\n",
    "            np.random.seed(run)\n",
    "            random.seed(run)\n",
    "\n",
    "            model = GCNAE(\n",
    "                in_feats=pca_size,\n",
    "                n_hidden=hidden_dim,\n",
    "                n_layers=1,\n",
    "                activation=activation,\n",
    "                dropout=0.1,\n",
    "                hidden=None,\n",
    "                hidden_relu=False,\n",
    "                hidden_bn=False,\n",
    "            ).to(device)\n",
    "\n",
    "            # 替换 GNN 层\n",
    "            for i in range(len(model.layers)):\n",
    "                model.layers[i] = gnn_layer(\n",
    "                    in_channels=pca_size if i == 0 else hidden_dim,\n",
    "                    out_channels=hidden_dim,\n",
    "                )\n",
    "\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "            print(f\">> Training Model: {model_name} | Run: {run}\")\n",
    "\n",
    "            # 模型训练\n",
    "            scores = train(\n",
    "                model=model,\n",
    "                optimizer=optim,\n",
    "                n_epochs=epochs,\n",
    "                dataloader=dataloader,\n",
    "                n_clusters=n_clusters,\n",
    "                plot=False,\n",
    "                cluster=[\"KMeans\", \"Leiden\"],\n",
    "            )\n",
    "\n",
    "            # 确保分数是字典类型，转为 DataFrame\n",
    "            scores_df = pd.DataFrame([scores])\n",
    "\n",
    "            # 记录结果\n",
    "            scores_df[\"dataset\"] = dataset\n",
    "            scores_df[\"run\"] = run\n",
    "            scores_df[\"nb_genes\"] = nb_genes\n",
    "            scores_df[\"hidden_dim\"] = hidden_dim\n",
    "            scores_df[\"model_name\"] = model_name\n",
    "            results = pd.concat([results, scores_df], ignore_index=True)\n",
    "\n",
    "            # 保存结果\n",
    "            results.to_pickle(f\"./{category}_graph_networks.pkl\")\n",
    "\n",
    "# 汇总和显示结果\n",
    "print(\"Mean results grouped by model_name:\")\n",
    "numeric_results = results.select_dtypes(include=[np.number])  # 仅保留数值列\n",
    "print(numeric_results.groupby(results[\"model_name\"]).mean())\n",
    "\n",
    "print(\"Mean results grouped by dataset:\")\n",
    "print(numeric_results.groupby(results[\"dataset\"]).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
